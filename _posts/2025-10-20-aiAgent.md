---
author: taiyeong.song
category: pipeline
layout: post
title: AI Agent
---

## Environments

### UV

#### How to install

- definition : module for managing project ! (better than pip, pyenv, poetry, virtualenv ...)
- [How to install](https://docs.astral.sh/uv/getting-started/installation/)

#### How to use

- Initialize a project

```batch
cd {directory}

// Create a folder named prj_name, and init uv under the folder
uv init {prj_name} 

// init uv at current folder
uv init 
```

- Fetch and setup other project dependencies

```batch
// Copy pyproject.toml file into your project folder
// And then,
uv sync # at the folder
```

- Add new package without pyproject.toml

```batch
uv add {package_name}
```

> **uv.lock File**
> - After setting up dependencies with `add` or `sync`, There might be a a file named uv.lock. And the file is designed to let system know the sub-dependencies of the main dependencies which are specidifed under pyproject.toml


### Jupyter

#### How to install

1. Install jupyter extension in vscode
2. Install ipykernel python module using `uv`

    ```batch
    // --dev argumnet is to install the module only for developer
    uv add ipykernel --dev
    ```

#### How to use

1. Create `.ipynb` file with main or with other name.
2. Select `venv` which is created by uv

## OpenAI Billing

- [OpenAI billing page](https://platform.openai.com/settings/organization)
- $30-$50 might be enough to move forward

## Set up project

1. Create folder
2. Initialize uv

    ```batch
    uv init
    ```

3. Copy `pyproject.toml` if it is provided.
4. Synchronize current project's dependencies with dipendencies which are specified pyproject.toml 

    - [Troubleshooting a case - OS error 396 when using OneDrive](https://github.com/astral-sh/uv/issues/7906)

    ```batch
    uv sync // if not in Onedrive
    uv sync --python 3.12 // crewai and other package have dependencies on python 3.12

    // If you're using OneDrive of Windows
    // 1. Not use hardlink
    uv sync --link-mode=copy # do not use hardlink 
    
    // 2. Clean cache and do sync
    uv cache clean
    uv sync
    ```

5. Set vscode's venv to uv's venv
6. Create `.env file` and add OPENAI_API_KEY (you can use any other name as env variable)

    ```python
    os.getenv("OPENAI_API_KEY") # it will return the key
    ```
7. Run a python code

    ```batch
    uv run {python_code}.py
    uv run --python 3.12 {python_code}.py
    ```


## Build your first AI response

- [a list of model that gpt need to be fed](https://platform.openai.com/docs/pricing)

- How to get response from `the selected model` by using `openai module`

```python

# Create client to link to openai
import openai
client = openai.OpenAI()

# Arguments
# - model : go to prcing page, and then choose one of the models
# - messages : a list of dict need to be fed into this argument
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
            "role" : "user",
            "content" : "How to build usd asset assembly in houdini ?",
        }
    ]
)

# Following that, just retrieve message from choice object
choice = response.choices[0]
choice.message.content
```

## AI Agent ! what is that ?

- Definition : A system that handle with question or problem on behalf of user
- And, AI Agent is an AI, when user asks 

    ```python
    """
    I have the following functions in my system.

    `get_weather`
    `get_currency`
    `get_news`

    All of them receive the name of a country as an argument (i.e get_news('spain'))

    Please answer with the name of the function that you would like me to run.

    Please say nothing else, just the name of the function with the arguments.

    Answer the following question:

    What is the weather in Greece ?
    """
    ```
- not ask
    ```python
    """
    How to get a weather in Greece by using functions below ?
        `get_weather`
        `get_currency`
        `get_news`
    """
    ```

- if so, it returns 
    - ![answer01](/assets/AIAgent/what_is_aiAgent_01.png)
    - instead of 
        ```
        "To get the weather in Greece using a hypothetical `get_weather` function, you would typically follow these steps:\n\n1. **Check Parameters Required**: Understand what parameters the `get_weather` function accepts. Common parameters might include the location (in this case, Greece), the date for which you want the weather, and perhaps the type of data you need (current weather, forecast, etc.).\n\n2. **Call the Function**: Use the `get_weather` function with the appropriate arguments.\n\nHereâ€™s a simple example in Python (assuming these functions are provided in a package or module):\n\n```python\n# Example of fetching weather in Greece\n\n# Assume these functions are defined in a module named 'weather_api'\nfrom weather_api import get_weather\n\n# Get current weather in Greece\ngreece_weather = get_weather(location='Greece')\n\n# Output the weather\nprint(greece_weather)\n```\n\n### Example Output\nThe output might be a dictionary or an object with weather details such as temperature, humidity, condition (sunny, rainy, etc.).\n\n### Additional Options\nIf you want to retrieve related information, you could also use the `get_currency` and `get_news` functions in a similar manner:\n\n```python\n# Example of fetching currency and news related to Greece\n\n# Get the currency information\nfrom finance_api import get_currency\n\ngreece_currency = get_currency(country='Greece')\nprint(greece_currency)\n\n# Get news related to Greece\nfrom news_api import get_news\n\ngreece_news = get_news(topic='Greece')\nprint(greece_news)\n```\n\n### Summary\n- Use `get_weather` to fetch weather data for Greece.\n- Use `get_currency` to fetch currency details (like the Euro).\n- Use `get_news` to get the latest news related to Greece.\n\nBe sure to check the documentation for the specific API or library you're using to understand the exact function signatures and available parameters!"
        ```
- `Prompt` is really important !

## Adding memory
- Goal : How to make the Ai `remember` previous answers
- Problem ! : With the code above - [Build your first AI response](#build-your-first-ai-response), it will not remember user's previous question like
    ```text
    user : My name is Taiyeong
    AI : Hi Taiyeong, what can I help you?
    user : what is my name
    AI : Sorry...
    ```
- Solution : Append user input (str) and AI reponse (str or object) to `list` or other type of variable

    ```python
    msg_stack = []

    # Ask question to ai
    msg_stack.append({"role":"user", "content":user_msg})
    response = client.chat.completions.create(model="gpt-4o-mini", messages=msg_stack)

    # After that, append the answer to the message stack 
    answer = response.choices[0].message.content
    msg_stack.append({"role":"assistant", "content":answer})

    # Get another question
    msg_stack.append({"role":"user", "content":user_msg})
    ```
    
    - Fianl code

    ```python
    from typing import List
    import openai
    client = openai.OpenAI()

    def call_ai(msg_stack :List[dict]) -> str:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=msg_stack
        )
        answer = "Sorry, I didn't get it. Can you explan more detail ? "
        if response:
            answer = response.choices[0].message.content
        msg_stack.append(
                {"role":"assistant", "content":answer}
            )
        return answer


    msg_stack = []
    while True:
        user_msg = input("Send a message to the LLM...")
        if user_msg == "quit" or user_msg == "q":
            print(f"Ai Answer : Ok, I will close this conversation now, but if you need any help, feel free to reach out to me :)")
            break
        else:
            msg_stack.append(
                {"role":"user", "content":user_msg}
            )
            answer_from_ai = call_ai(msg_stack)
            print(f"User ask : {user_msg}")
            print(f"Ai Answer : {answer_from_ai}")
    ```

## Adding Tools 

- Goal : Make the Ai give purpose-oriented answer in terms of coding
    - not text-based answer but `answer based on api documents`

- How to ? - tools=TOOLS / "role": "tool" / "tool_call_id": tool_call.id / "tool_calls" ...
    1. Give tool schema to the ai
    2. Check if `response.choice[0].message.content` is None or not - it means the answer used tools and tools mapping
    3. Check `response.choice[0].message.tool_calls`. And then, give feedbacks to the ai
        - Append feedback two times
            1. functions and arguments that ai gave us
            2. returns that functions returned after running the functions
    - Register functions - Check `FUNCTION_MAP` variable below

```python
from openai.types.chat import ChatCompletionMessage


def get_weather(city):
    return "33 degrees celcius."


FUNCTION_MAP = {
    "get_weather": get_weather,
}


def process_ai_response(message: ChatCompletionMessage):

    if message.tool_calls:
        messages.append(
            {
                "role": "assistant",
                "content": message.content or "",
                "tool_calls": [
                    {
                        "id": tool_call.id,
                        "type": "function",
                        "function": {
                            "name": tool_call.function.name,
                            "arguments": tool_call.function.arguments,
                        },
                    }
                    for tool_call in message.tool_calls
                ],
            }
        )

        for tool_call in message.tool_calls:
            function_name = tool_call.function.name
            arguments = tool_call.function.arguments

            print(f"Calling function: {function_name} with {arguments}")

            try:
                arguments = json.loads(arguments)
            except json.JSONDecodeError:
                arguments = {}

            function_to_run = FUNCTION_MAP.get(function_name)

            result = function_to_run(**arguments)

            print(f"Ran {function_name} with args {arguments} for a result of {result}")

            messages.append(
                {
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": function_name,
                    "content": result,
                }
            )

        call_ai()
    else:
        messages.append({"role": "assistant", "content": message.content})
        print(f"AI: {message.content}")


def call_ai():
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        tools=TOOLS,
    )
    process_ai_response(response.choices[0].message)
```

## CrewAI

### Terminolgoy
- crew : a group of agents
- agent : it is a thing that help user get answer based on purpose of question
- task : task is task

### Basic workflow of CrewAI

- Use decorators : CrewBase / agent / task / crew
    - There are three parts - **main.py / tools.py / agents.yaml and tasks.yaml**
    - **The CrewBase decorator collects agents and tasks automatically**

#### Main.py
- This main code feed yaml files and tools.py

    ```python
    import dotenv

    dotenv.load_dotenv()

    from crewai import Crew, Agent, Task
    from crewai.project import CrewBase, agent, task, crew
    from tools import count_letters


    @CrewBase
    class TranslatorCrew:

        @agent
        def translator_agent(self):
            return Agent(
                config=self.agents_config["translator_agent"],
            )

        # This agent is using `tools`
        @agent
        def counter_agent(self):
            return Agent(
                config=self.agents_config["counter_agent"],
                tools=[count_letters],
            )

        @task
        def translate_task(self):
            return Task(
                config=self.tasks_config["translate_task"],
            )

        @task
        def retranslate_task(self):
            return Task(
                config=self.tasks_config["retranslate_task"],
            )

        @task
        def count_task(self):
            return Task(
                config=self.tasks_config["count_task"],
            )

        @crew
        def assemble_crew(self):
            return Crew(
                agents=self.agents,
                tasks=self.tasks,
                verbose=True,
            )


    TranslatorCrew().assemble_crew().kickoff(
        inputs={
            "sentence": "I'm Nico and I like to ride my bicicle in Napoli",
        }
    )
    ```

#### yaml files : how crewai use yaml files which are under config folder
- The folder name for these yaml file must be `config`
    - ![config_folder](/assets/AIAgent/config_for_agents_and_tasks.png)

- agents.yaml
    - [Crewai Agent attributes](https://docs.crewai.com/en/concepts/agents)

    ```yaml
    translator_agent:
        role: >
            Translator to translate from English to Italian
        goal: >
            To be a good and useful translator to avoid misunderstandings.
        backstory: >
            You grew up between New York and Palermo, you can speak two languages fluently, and you can detect the cultural differences.
    counter_agent:
        role: >
            To count the lenght of things.
        goal: >
            To be a good counter that never lies or makes things up.
        backstory: >
            You are a genius counter.
    ```

- tasks.yaml
    - [Crewai tasks attributes](https://docs.crewai.com/en/concepts/tasks)

    ```yaml
        translate_task:
            description: >
                Translate {sentence} from English to Italian without making mistakes.
            expected_output: >
                A well formatted translation from English to Italian using proper capitalization of names and places.
            agent: translator_agent

        retranslate_task:
            description: >
                Translate {sentence} from Italian to Greek without making mistakes.
            expected_output: >
                A well formatted translation from Italian to Greek using proper capitalization of names and places.
            agent: translator_agent

        count_task:
            description: >
                Count the amount of letters in a sentence.
            expected_output: >
                The number of letters in a sentence.
            agent: counter_agent
    ```

#### tools.py : how crewai use tools 
- Crewai has its own tools
    - [Crewai's tools](https://docs.crewai.com/en/tools/overview)
    - ![Crewai tools](/assets/AIAgent/crewai_tools.png)

- How to use user-defined-tools
    1. Create a function and add `tool` decorator for the function

        ```python
        from crewai.tools import tool


        @tool
        def count_letters(sentence: str):
            """
            This function is to count the amount of letters in a sentence.
            The input is a `sentence` string.
            The output is a number.
            """
            print("tool called with input:", sentence)
            return len(sentence)
        ```

    2. **yaml files** . Add specific `instruction` into `agents.yaml` and `tasks.yaml`

        - agents.yaml

            ```yaml
            counter_agent:
                role: >
                    To count the lenght of things.
                goal: >
                    To be a good counter that never lies or makes things up.
                backstory: >
                    You are a genius counter.
            ```
        
        - tasks.yaml

            ```yaml
            count_task:
                description: >
                    Count the amount of letters in a sentence.
                expected_output: >
                    The number of letters in a sentence.
                agent: counter_agent
            ```
    3. **Decorated functions** . Create `an agent function` and `a task function`

        ```python
            from tools import count_letters

            @CrewBase
            class TranslatorCrew:
                # ... 
                @agent
                def counter_agent(self):
                    return Agent(
                        config=self.agents_config["counter_agent"],
                        tools=[count_letters],
                    )

                @task
                def count_task(self):
                    return Task(
                        config=self.tasks_config["count_task"],
                    )
                # ...
        ```


## CrewAI 01: News Reader Agent

### Properties of two yaml files

#### Date / LLM / Markdown /  Output file / Create Directory

- Within the title, I'd write down ...
    - agetns.yaml
        - ![agent_properties](/assets/AIAgent/llm_property.png)
        - `inject_date` property : bool
        - `llm` property : str
    - tasks.yaml
        - ![task_properties](/assets/AIAgent/tast_properties.png)
        - `markdown` property : bool
        - `output_file` property
        - `create_directory` property

### SerperDevTool / playwright - sync_playwright / BeautifulSoup

- By using those modules, `Create tools` with tool decorator
- And, use the tools in main.py for an agent method


#### SuperDevTool

- Url : [Serper](https://serper.dev/)
    - Need to create an `acount`
    - Need to create and save an `API key`
    - Save the API key in `.env file`

- Definition
    - A tool for searching something from Goolge, created by CrewAI
    - Example

        ```python
        from crewai_tools import SerperDevTool

        tool = SerperDevTool()

        result = tool.run(search_query="ChatGPT")
        print(result)
        ```

#### Playwright

- Definition
    - Created by Microsoft
    - Opensource browser automating library
    - Allow user to control Chrominum.Firefox.WebKit
    - Use for web-testing, web-scrapping, UI-automation ...

#### `Sync` vs `Async`, provided by Playwright

- PlaywrightëŠ” ë‘ ê°€ì§€ API ìŠ¤íƒ€ì¼ì„ ì œê³µí•´ìš”:

    | API ìŠ¤íƒ€ì¼ | ëª¨ë“ˆ | íŠ¹ì§• |
    |-----------|------|------|
    | **ë™ê¸°(Sync)** | `playwright.sync_api` | ì¼ë°˜ì ì¸ Python ì½”ë“œì²˜ëŸ¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë¨ |
    | **ë¹„ë™ê¸°(Async)** | `playwright.async_api` | `async/await` ê¸°ë°˜, ê³ ì„±ëŠ¥ ë³‘ë ¬ ì‘ì—… ê°€ëŠ¥ |

    - **ë™ê¸° APIëŠ” ì§ê´€ì ì´ê³  ë””ë²„ê¹…ì´ ì‰¬ì›Œì„œ** ë¹ ë¥´ê²Œ ì‘ì—…í•˜ê¸° ì¢‹ì•„ìš”.


- ğŸ­ `playwright.sync_api` ì™€ `sync_playwright`ë€?

    - `playwright.sync_api`ëŠ” **Playwrightì˜ ë™ê¸°(Synchronous) API ë²„ì „**ì„ ì œê³µí•˜ëŠ” ëª¨ë“ˆì´ì—ìš”.`sync_playwright`ëŠ” **Playwrightë¥¼ ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ í•¨ìˆ˜**ì…ë‹ˆë‹¤.


    - ğŸš€ ê¸°ë³¸ ì‚¬ìš© ì˜ˆì‹œ

        ```python
        from playwright.sync_api import sync_playwright

        with sync_playwright() as p:
            browser = p.chromium.launch()
            page = browser.new_page()
            page.goto("https://playwright.dev")
            print(page.title())
            browser.close()
        ```
        
        1. Playwright ì‹¤í–‰
        2. Chromium ë¸Œë¼ìš°ì € ì‹¤í–‰
        3. ìƒˆ í˜ì´ì§€ ì—´ê¸°
        4. íŠ¹ì • URLë¡œ ì´ë™
        5. í˜ì´ì§€ ì œëª© ì¶œë ¥
        6. ë¸Œë¼ìš°ì € ì¢…ë£Œ


- `playwright.async_api`
    - Large-scale crawling

        ```python
        import asyncio
        import aiohttp
        from bs4 import BeautifulSoup

        class Crawler:
            def __init__(self, max_workers=20, max_concurrency=5):
                self.queue = asyncio.Queue()
                self.semaphore = asyncio.Semaphore(max_concurrency)
                self.max_workers = max_workers

            async def fetch(self, session, url):
                async with self.semaphore:
                    async with session.get(url) as resp:
                        return await resp.text()

            async def worker(self, session):
                while True:
                    try:
                        url = await asyncio.wait_for(self.queue.get(), timeout=3)
                    except asyncio.TimeoutError:
                        return

                    html = await self.fetch(session, url)
                    await self.parse(html)
                    self.queue.task_done()

            async def parse(self, html):
                soup = BeautifulSoup(html, "html.parser")
                # ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥ ë¡œì§
                pass

            async def run(self, start_urls):
                async with aiohttp.ClientSession() as session:
                    for url in start_urls:
                        await self.queue.put(url)

                    workers = [
                        asyncio.create_task(self.worker(session))
                        for _ in range(self.max_workers)
                    ]

                    await self.queue.join()

                    for w in workers:
                        w.cancel()

        asyncio.run(Crawler().run(["https://example.com"]))
        ```

## CrewAI 02: Job hunter agent

### Git

- [git repo](https://github.com/nomadcoders/ai-agents-masterclass/tree/master/job-hunter-agent)

### Agents and Tasks

* **When to use**: Use when defining the core logic of your AI application. Separating configuration (YAML) from execution logic (Python) allows for easier prompting updates without touching the codebase.
* **Key Concept**: The `agent` property in `tasks.yaml` explicitly links a specific task to the agent responsible for executing it.

#### How to use

* **Explanation**:
    1. Define agent personas in `agents.yaml` (role, goal, backstory).
    2. Define task instructions in `tasks.yaml`, ensuring the `agent` key matches the agent's name.
    3. Use the `@crew`, `@agent`, and `@task` decorators in `main.py` to map these configurations to Python methods.


* **Code block**:

    ```yaml
    # config/agents.yaml
    job_search_agent:
    role: >
        Senior Job Market Research Specialist
    goal: >
        Discover and analyze relevant job opportunities...
    # ... (backstory omitted)

    ```


    ```yaml
    # config/tasks.yaml
    job_extraction_task:
    description: >
        Find and extract {level} level {position} jobs in {location}.
        # ...
    expected_output: >
        A JSON object matching the `JobList` schema.
    agent: job_search_agent  # <--- Links task to specific agent

    ```


    ```python
    # main.py
    @agent
    def job_search_agent(self):
        return Agent(
            config=self.agents_config["job_search_agent"],
            tools=[web_search_tool],
        )

    @task
    def job_extraction_task(self):
        return Task(
            config=self.tasks_config["job_extraction_task"],
            output_pydantic=JobList,
        )

    ```


* **Code block (Recommended Practice)**
(Use `CrewBase` class structure to automatically load YAML configs)

    ```python
    from crewai.project import CrewBase, agent, task, crew

    @CrewBase
    class JobHunterCrew:
        """JobHunterCrew crew"""
        agents_config = 'config/agents.yaml'
        tasks_config = 'config/tasks.yaml'

        # The decorators automatically match the function name 
        # to the key in the YAML file.

    ```



---

### Structured Outputs

* **When to use**: Use when you need the AI to return data in a reliable, machine-readable format (JSON/Object) instead of plain text. This is critical for downstream processing or API integrations.
* **Key Concept**: The `output_pydantic` argument enforces a strict schema defined by a `BaseModel`.

#### How to use

* **Explanation**:
1. Define a class inheriting from `pydantic.BaseModel` in `models.py`.
2. Import this model in your `main.py`.
3. Pass the class to the `output_pydantic` parameter in the `@task` definition.


* **Code block**:

    ```python
    # models.py
    from pydantic import BaseModel
    from typing import List

    class Job(BaseModel):
        job_title: str
        company_name: str
        job_location: str
        # ...

    class JobList(BaseModel):
        jobs: List[Job]

    ```


    ```python
    # main.py
    from models import JobList

    @task
    def job_extraction_task(self):
        return Task(
            config=self.tasks_config["job_extraction_task"],
            output_pydantic=JobList, # <--- Enforces structure
        )

    ```


* **Code block (Recommended Practice)**
(Add descriptions to Pydantic fields to improve LLM accuracy)

    ```python
    from pydantic import BaseModel, Field

    class Job(BaseModel):
        job_title: str = Field(..., description="The official title of the position")
        is_remote_friendly: bool = Field(..., description="True if remote work is explicitly allowed")

    ```



---

### Context

* **When to use**: Use when a task requires the specific output of a *previous* task to function correctly. This establishes a dependency chain.
* **Key Concept**: The `context` argument acts as a pipe, feeding the results of prior tasks directly into the prompt of the current task.

#### How to use

* **Explanation**:
1. Identify the task that produces the data (e.g., `job_selection_task`).
2. Identify the receiver task (e.g., `resume_rewriting_task`).
3. In `main.py`, pass the producer task method call into the `context` list of the receiver task.
4. In `tasks.yaml`, reference the input data clearly (e.g., "Given the selected job...").


* **Code block**

    ```python
    # main.py
    @task
    def resume_rewriting_task(self):
        return Task(
            config=self.tasks_config["resume_rewriting_task"],
            context=[
                self.job_selection_task(), # <--- Feeds output from job_selection_task
            ],
        )

    ```


    ```yaml
    # config/tasks.yaml
    resume_rewriting_task:
    description: >
        Given the user's real resume... and the selected job (ChosenJob), 
        your task is to rewrite the existing resume...
        # ...

    ```


* **Code block (Recommended Practice)**
(Explicitly type-hint the context in the agent prompt for clarity)

    ```yaml
    # config/tasks.yaml
    resume_rewriting_task:
    description: >
        INPUT DATA:
        - Selected Job Details: {job_selection_task_output}

        TASK:
        Rewrite the resume to align with the Selected Job Details above.

    ```



---

### Firecrawl Tool

* **When to use**: Use specifically for extracting clean content from websites, bypassing common bot protections. It is optimized for LLM ingestion by returning Markdown.
* **Key Concept**: The `FirecrawlApp` handles the connection, and `ScrapeOptions` formats the output.

#### How to use

* **Explanation**:
1. Obtain an API key from [firecrawl.dev](https://www.firecrawl.dev).
2. Instantiate `FirecrawlApp` with the key.
3. Use the `.search()` method to query the web.
4. Use `ScrapeOptions(formats=["markdown"])` to ensure the text is AI-readable.
5. Clean the output (regex) to remove noise like excessive newlines or unrelated links.


* **Code block**:

    ```python
    # tools.py
    from firecrawl import FirecrawlApp, ScrapeOptions
    import os, re

    @tool
    def web_search_tool(query: str):
        app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))

        response = app.search(
            query=query,
            limit=5,
            scrape_options=ScrapeOptions(
                formats=["markdown"],
            ),
        )

        # ... (Cleaning logic follows)

    ```


* **Code block (Recommended Practice)**
(Use `.scrape()` directly if you already have the specific URL from a previous search, rather than searching again)

    ```python
    @tool
    def specific_page_scraper(url: str):
        app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))
        response = app.scrape(
            url=url,
            scrape_options=ScrapeOptions(formats=["markdown"])
        )
        return response['markdown']

    ```



---

### Knowledge Sources

* **When to use**: Use when agents need access to static, domain-specific data (like a resume, policy document, or codebase) that exceeds the standard prompt context window or requires retrieval.
* **Key Concept**: Sources can be raw strings or files. The `TextFileKnowledgeSource` is used for reading local files.

#### How to use

* **Explanation**:
1. Import `TextFileKnowledgeSource`.
2. Initialize it with the path to your file(s).
3. Pass this source object to the `knowledge_sources` list in the `Agent` definition.


* **Code block**:

    ```python
    # main.py
    from crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource

    # Define source
    resume_knowledge = TextFileKnowledgeSource(
        file_paths=[
            "resume.txt",
        ]
    )

    @agent
    def job_matching_agent(self):
        return Agent(
            config=self.agents_config["job_matching_agent"],
            knowledge_sources=[resume_knowledge], # <--- Agent gets access here
        )

    ```


* **Code block (Recommended Practice)**
(Using StringKnowledgeSource for dynamic data passed at runtime)

    ```python
    from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource

    def create_dynamic_knowledge(user_input_text):
        return StringKnowledgeSource(
            content=user_input_text,
            metadata={"source": "user_input"}
        )

    ```



---

### Results of task in a form of pydantic

* **When to use**: Use to programmatically access the structured data returned by the agents after the crew finishes execution. This allows you to inspect, validate, or save the specific object rather than a raw string.
* **Key Concept**: The `kickoff()` method returns a result object containing `tasks_output`. Each output has a `.pydantic` property if the task was configured with `output_pydantic`.

#### How to use

* **Explanation**:
1. Execute the crew using `.kickoff()`.
2. Iterate through `result.tasks_output`.
3. Access the `.pydantic` attribute to get the instantiated Pydantic object (e.g., `JobList`, `ChosenJob`).


* **Code block**:

    ```python
    # main.py
    result = (
        JobHunterCrew()
        .crew()
        .kickoff(
            inputs={
                "level": "Senior",
                "position": "Golang Developer",
                "location": "Netherlands",
            }
        )
    )

    # Debugging / Accessing the object
    for task_output in result.tasks_output:
        print(task_output.pydantic)

    ```


* **Code block (Recommended Practice)**
(Type checking the output before using it)

    ```python
    from models import ChosenJob

    for task_output in result.tasks_output:
        if isinstance(task_output.pydantic, ChosenJob):
            print(f"Selected Job: {task_output.pydantic.job.job_title}")
            # Save to database or pass to next system

    ```


## CrewAI 03-1 : Content Pipeline Agent

### Flow

* **Definition or When to use**: **ë¹„ì„ í˜•(Non-linear) ì›Œí¬í”Œë¡œìš°**ë¥¼ ì„¤ê³„í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¨ìˆœí•œ ìˆœì°¨ ì‹¤í–‰ì„ ë„˜ì–´, ì—¬ëŸ¬ Crew(Agentì™€ Taskì˜ ì§‘í•©)ë¥¼ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ê³  ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ì»¨í…Œì´ë„ˆ ì—­í• ì„ í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* `Flow` í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ì •ì˜í•©ë‹ˆë‹¤.
* ì œë„¤ë¦­ íƒ€ì…ìœ¼ë¡œ ìƒíƒœ(State) í´ë˜ìŠ¤ë¥¼ ì§€ì •í•˜ì—¬ íƒ€ì… ì•ˆì •ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* ë‚´ë¶€ì— ì—ì´ì „íŠ¸, íƒœìŠ¤í¬, ë¼ìš°íŒ… ë¡œì§ì„ í¬í•¨í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture
    from crewai.flow.flow import Flow, listen, start, router, and_, or_
    from pydantic import BaseModel

    class MyFirstFlowState(BaseModel):
        user_id: int = 1
        is_admin: bool = False

    class MyFirstFlow(Flow[MyFirstFlowState]):
        # ... ë©”ì„œë“œ ì •ì˜ ...
        pass

    flow = MyFirstFlow()
    flow.kickoff()

    ```


* **Code block(Recommended Practice)**
(ë³µì¡í•œ ë¡œì§ì˜ ê²½ìš°, Flowë¥¼ ë³„ë„ íŒŒì¼ë¡œ ë¶„ë¦¬í•˜ê³  ì‹¤í–‰ ê²°ê³¼ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬í•˜ëŠ” ë°©ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    if __name__ == "__main__":
        flow = MyFirstFlow()
        result = flow.kickoff()
        print(f"Flow Execution Result: {result}")

    ```



### listen

* **Definition or When to use**: íŠ¹ì • ì‘ì—…(ë©”ì„œë“œ)ì´ ì™„ë£Œë˜ê±°ë‚˜ íŠ¹ì • ì‹ í˜¸(ë°˜í™˜ ê°’)ê°€ ë°œìƒí–ˆì„ ë•Œ **í›„ì† ì‘ì—…ì„ íŠ¸ë¦¬ê±°**í•˜ëŠ” ë°ì½”ë ˆì´í„°ì…ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* ë©”ì„œë“œ ìì²´ë¥¼ ì¸ìë¡œ ë°›ìœ¼ë©´ í•´ë‹¹ ë©”ì„œë“œ ì™„ë£Œ í›„ ì‹¤í–‰ë©ë‹ˆë‹¤.
* ë¬¸ìì—´(String)ì„ ì¸ìë¡œ ë°›ìœ¼ë©´, `router` ë“±ì—ì„œ ë°˜í™˜ëœ ê°’ê³¼ ì¼ì¹˜í•  ë•Œ ì‹¤í–‰ë©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture
    @listen(first)
    def second(self):
        self.state.user_id = 2
        print("world")

    @listen("even")
    def handle_even(self):
        print("even")

    ```


* **Code block(Recommended Practice)**
(ë¬¸ìì—´ í•˜ë“œì½”ë”© ëŒ€ì‹  Enumì„ ì‚¬ìš©í•˜ì—¬ ì˜¤íƒ€ë¥¼ ë°©ì§€í•˜ê³  ìœ ì§€ë³´ìˆ˜ì„±ì„ ë†’ì´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    from enum import Enum

    class FlowStatus(Enum):
        EVEN = "even"
        ODD = "odd"

    # ... routerì—ì„œ FlowStatus.EVEN.value ë°˜í™˜ ...

    @listen(FlowStatus.EVEN.value)
    def handle_even(self):
        # ë¡œì§ ìˆ˜í–‰
        pass

    ```



### or_ / and_

* **Definition or When to use**: ì—¬ëŸ¬ ì‘ì—…ì˜ íë¦„ì„ ì œì–´í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. `and_`ëŠ” **ëª¨ë“  ì„ í–‰ ì‘ì—… ì™„ë£Œ** ì‹œ, `or_`ëŠ” **í•˜ë‚˜ë¼ë„ ì™„ë£Œ** ì‹œ í›„ì† ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* `@listen` ë°ì½”ë ˆì´í„° ë‚´ë¶€ì—ì„œ ë‘ ê°œ ì´ìƒì˜ ë©”ì„œë“œë¥¼ ë…¼ë¦¬ ì—°ì‚°ìë¡œ ë¬¶ì–´ ì‚¬ìš©í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture
    @listen(and_(second, third))
    def final(self):
        print(":)")

    ```


* **Code block(Recommended Practice)**
(ê°€ë…ì„±ì„ ìœ„í•´ ê²°í•© ì¡°ê±´ì´ ë³µì¡í•  ê²½ìš°, ë³„ë„ ë³€ìˆ˜ë¡œ ë¶„ë¦¬í•˜ê±°ë‚˜ ì£¼ì„ì„ ëª…ì‹œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    # secondì™€ third ì‘ì—…ì´ ëª¨ë‘ ì™„ë£Œë˜ì–´ì•¼ ë°ì´í„° ì§‘ê³„(aggregate) ì‹œì‘
    pre_requisites = and_(second, third)

    @listen(pre_requisites)
    def aggregate_results(self):
        # ê²°ê³¼ ì²˜ë¦¬
        pass

    ```



### router

* **Definition or When to use**: **ì¡°ê±´ë¶€ ë¶„ê¸°(Conditional Logic)**ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ(State)ë‚˜ ì´ì „ ì‘ì—… ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ì‹¤í–‰ ê²½ë¡œë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* `@router` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ê¸°ì  ë©”ì„œë“œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
* ë°˜í™˜ëœ ê°’(ì£¼ë¡œ ë¬¸ìì—´)ì€ `@listen`ìœ¼ë¡œ ëŒ€ê¸° ì¤‘ì¸ ë‹¤ë¥¸ ë©”ì„œë“œë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture
    @router(final)
    def route(self):
        if self.state.is_admin:
            return "even"
        else:
            return "odd"

    ```


* **Code block(Recommended Practice)**
(ëª…í™•í•œ íë¦„ ì œì–´ë¥¼ ìœ„í•´ `match-case` ë¬¸(Python 3.10+)ì„ í™œìš©í•˜ë©´ ê°€ë…ì„±ì´ í–¥ìƒë©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    @router(final)
    def route(self):
        match self.state.is_admin:
            case True:
                return "even"
            case False:
                return "odd"

    ```



### self.state

* **Definition or When to use**: Flow ë‚´ì˜ ì—¬ëŸ¬ ë‹¨ê³„(Step) ê°„ì— **ë°ì´í„°ë¥¼ ê³µìœ í•˜ê³  ìœ ì§€**í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤. Pydanticì˜ `BaseModel`ì„ í™œìš©í•˜ì—¬ ë°ì´í„° êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* Flow í´ë˜ìŠ¤ ì •ì˜ ì‹œ ì œë„¤ë¦­ íƒ€ì…ìœ¼ë¡œ ìƒíƒœ ëª¨ë¸ì„ ì£¼ì…í•©ë‹ˆë‹¤ (`Flow[MyFirstFlowState]`).
* ë©”ì„œë“œ ë‚´ë¶€ì—ì„œ `self.state`ë¥¼ í†µí•´ ì½ê¸° ë° ì“°ê¸°ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture
    class MyFirstFlowState(BaseModel):
        user_id: int = 1
        is_admin: bool = False

    # ... (ë‚´ë¶€ ë©”ì„œë“œì—ì„œ ì‚¬ìš©) ...
    def first(self):
        print(self.state.user_id) # ì½ê¸°

    def second(self):
        self.state.user_id = 2    # ì“°ê¸°

    ```


* **Code block(Recommended Practice)**
(State ë³€ê²½ ì‹œ ìœ íš¨ì„± ê²€ì‚¬ ë¡œì§ì„ Pydantic ëª¨ë¸ ë‚´ì— ì¶”ê°€í•˜ì—¬ ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    from pydantic import field_validator

    class MyFirstFlowState(BaseModel):
        user_id: int = 1

        @field_validator('user_id')
        def id_must_be_positive(cls, v):
            if v < 0:
                raise ValueError('must be positive')
            return v

    ```



### recommendation (Design & Visualization)

* **Definition or When to use**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ì „, ì „ì²´ êµ¬ì¡°ë¥¼ **ì‹œê°í™”í•˜ì—¬ ê²€ì¦**í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* êµ¬í˜„ ì´ˆê¸°ì—ëŠ” ì‹¤ì œ ë¡œì§ ì—†ì´ ë¹ˆ ë©”ì„œë“œ(pass)ì™€ ë°ì½”ë ˆì´í„°ë§Œìœ¼ë¡œ ë¼ˆëŒ€ë¥¼ ì¡ìŠµë‹ˆë‹¤.
* `flow.plot()`ì„ í˜¸ì¶œí•˜ì—¬ HTML íŒŒì¼ë¡œ íë¦„ë„ë¥¼ ìƒì„±, êµ¬ì¡°ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture
    flow = MyFirstFlow()
    flow.plot()

    ```


* **Code block(Recommended Practice)**
(ì¶œë ¥ íŒŒì¼ëª…ì„ ì§€ì •í•˜ì—¬ ë²„ì „ë³„ë¡œ ë‹¤ì´ì–´ê·¸ë¨ì„ ê´€ë¦¬í•˜ê±°ë‚˜ íŠ¹ì • ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    # ì›Œí¬í”Œë¡œìš° êµ¬ì¡°ë¥¼ ì‹œê°í™”í•˜ì—¬ 'flow_structure.html'ë¡œ ì €ì¥
    flow.plot(filename="flow_structure") 

    ```
---

## CrewAI 03-2 : Content Pipeline Agent

### Refinement Loop (Loop-based Feedback)

* **Definition or When to use**: **í’ˆì§ˆ ë³´ì¦(QA) ë£¨í”„**ë¥¼ êµ¬í˜„í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ìƒì„±ëœ ê²°ê³¼ë¬¼ì´ íŠ¹ì • ê¸°ì¤€(Score)ì„ ì¶©ì¡±í•˜ì§€ ëª»í•  ê²½ìš°, í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ë‹¤ì‹œ ìƒì„± ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* `router` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€ ì ìˆ˜(`score`)ë¥¼ í™•ì¸í•˜ê³ , ê¸°ì¤€ ë¯¸ë‹¬ ì‹œ "ì¬ì‘ì—… ì‹ í˜¸(ì˜ˆ: remake_blog)"ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
* ìƒì„± ë©”ì„œë“œ(ì˜ˆ: `handle_make_blog`)ëŠ” `listen(or_("start", "remake"))`ë¥¼ í†µí•´ ì´ˆê¸° ì‹¤í–‰ê³¼ ì¬ì‘ì—… ì‹ í˜¸ë¥¼ ëª¨ë‘ ìˆ˜ì‹ í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture (main.py)
    @router(or_(check_seo, check_virality))
    def score_router(self):

        content_type = self.state.content_type
        score = self.state.score

        if score.score >= 7:
            return "check_passed"
        else:
            if content_type == "blog":
                return "remake_blog"
            elif content_type == "linkedin":
                return "remake_linkedin_post"
            else:
                return "remake_tweet"

    @listen(or_("make_blog", "remake_blog"))
    def handle_make_blog(self):
        # ... ìƒì„± ë¡œì§ ...

    @listen("check_passed")
    def finalize_content(self):
        # ... ë§ˆë¬´ë¦¬ ë¡œì§ ...

    ```


* **Code block(Recommended Practice)**
(ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ `retry_count` ì œí•œì„ ìƒíƒœ(State)ì— ì¶”ê°€í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    class ContentPipelineState(BaseModel):
        retry_count: int = 0
        max_retries: int = 3
        # ... existing fields ...

    @router(or_(check_seo, check_virality))
    def score_router(self):
        if self.state.score.score >= 7 or self.state.retry_count >= self.state.max_retries:
            return "check_passed"

        self.state.retry_count += 1
        # ... ë¦¬í„´ ë¡œì§ ...

    ```

---

### LLM Class (Direct LLM Usage)

* **Definition or When to use**: **ë‹¨ìˆœ ë°ì´í„° ë³€í™˜, í¬ë§·íŒ…, êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±**ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. `Agent`ì™€ ë‹¬ë¦¬ í˜ë¥´ì†Œë‚˜, ë„êµ¬(Tool), ë³µì¡í•œ ì¶”ë¡  ê³¼ì •(Thought Loop) ì—†ì´ ëª¨ë¸ì˜ raw capabilityë§Œ ë¹ ë¥´ê²Œ í™œìš©í•  ë•Œ ì í•©í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* `crewai.LLM` í´ë˜ìŠ¤ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
* `response_format` ì¸ìì— Pydantic ëª¨ë¸ì„ ì „ë‹¬í•˜ì—¬ JSON ì¶œë ¥ì„ ê°•ì œí•©ë‹ˆë‹¤.
* `.call()` ë©”ì„œë“œë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture (main.py)
    from crewai import LLM

    llm = LLM(model="openai/o4-mini", response_format=BlogPost)

    result = llm.call(
        f"""
        Make a blog post with SEO practices on the topic {self.state.topic} using the following research:
        ...
        """
    )
    self.state.blog_post = BlogPost.model_validate_json(result)

    ```


* **Code block(Recommended Practice)**
(ëª¨ë¸ ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•´ ë‹¨ìˆœ ì‘ì—…ì—ëŠ” ê°€ë²¼ìš´ ëª¨ë¸ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    # ë³µì¡í•œ ì¶”ë¡ ì´ í•„ìš” ì—†ëŠ” í¬ë§·íŒ… ì‘ì—…ì—ëŠ” gpt-4o-mini ë“± ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš© ê¶Œì¥
    llm = LLM(model="gpt-4o-mini", response_format=BlogPost)

    ```

---

### Structured Prompting (Context Isolation)

* **Definition or When to use**: LLMì—ê²Œ ì…ë ¥ë˜ëŠ” **ë°ì´í„°(Context)ì™€ ì§€ì‹œì‚¬í•­(Instruction)ì„ ëª…í™•íˆ êµ¬ë¶„**í•´ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. XML ìŠ¤íƒ€ì¼ íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ë°ì´í„°ì˜ ê²½ê³„ë¥¼ ëª…í™•íˆ ì¸ì‹í•˜ê²Œ í•©ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* í”„ë¡¬í”„íŠ¸ ë‚´ì— `<tagname>`ê³¼ `</tagname>`ì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ë°ì´í„°ë¥¼ ê°ìŒ‰ë‹ˆë‹¤.
* íŠ¹íˆ, ì…ë ¥ ë°ì´í„°(`self.state.research`)ì— ì¤„ë°”ê¿ˆì´ë‚˜ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆì„ ë•Œ í”„ë¡¬í”„íŠ¸ ì˜¤ì‘ë™ì„ ë°©ì§€í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture (main.py)
    result = llm.call(
        f"""
        Make a blog post ... using the following research:

        <research>
        ================
        {self.state.research}
        ================
        </research>
        """
    )

    ```


* **Code block(Recommended Practice)**
(í”„ë¡¬í”„íŠ¸ê°€ ê¸¸ì–´ì§ˆ ê²½ìš° `dedent`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œ ê°€ë…ì„±ì„ ë†’ì´ê³  ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    from textwrap import dedent

    prompt = dedent(f"""
        Analyze the following content clearly.

        <content>
        {self.state.research}
        </content>
    """)

    ```

---

### kickoff_for_each : Sub-Crew Execution

* **Definition or When to use**: Flow ë‚´ì—ì„œ **ë…ë¦½ì ì¸ ì—ì´ì „íŠ¸ íŒ€(Crew)**ì„ ì„œë¸Œë£¨í‹´ì²˜ëŸ¼ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
* **`kickoff()`**: ë‹¨ì¼ ì…ë ¥ì— ëŒ€í•´ Crewë¥¼ 1íšŒ ì‹¤í–‰í•©ë‹ˆë‹¤. (ë³¸ ê°•ì˜ ì½”ë“œì—ì„œ ì‚¬ìš©ë¨)
* **`kickoff_for_each()`**: ì…ë ¥ ë¦¬ìŠ¤íŠ¸(List)ê°€ ìˆì„ ë•Œ, ê° í•­ëª©ì— ëŒ€í•´ ë³‘ë ¬ í˜¹ì€ ìˆœì°¨ì ìœ¼ë¡œ Crewë¥¼ ì‹¤í–‰í•´ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.



#### How to use

* **Explanation**:
* `@CrewBase`ë¡œ ì •ì˜ëœ í´ë˜ìŠ¤(ì˜ˆ: `SeoCrew`)ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•©ë‹ˆë‹¤.
* `.crew()` ë©”ì„œë“œë¡œ Crew ê°ì²´ë¥¼ ìƒì„±í•œ í›„ `.kickoff(inputs={...})`ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
* ê²°ê³¼ê°’ì˜ `pydantic` ì†ì„±ì„ í†µí•´ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ë°›ì•„ì˜µë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture (main.py)
    from seo_crew import SeoCrew

    result = (
        SeoCrew()
        .crew()
        .kickoff(
            inputs={
                "topic": self.state.topic,
                "blog_post": self.state.blog_post.model_dump_json(),
            }
        )
    )
    self.state.score = result.pydantic

    ```


* **Code block(Recommended Practice)**
(ë§Œì•½ ì—¬ëŸ¬ ê°œì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë™ì‹œì— ê²€ìˆ˜í•´ì•¼ í•œë‹¤ë©´ `kickoff_for_each`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    inputs_list = [{"topic": topic, "blog_post": post} for post in posts]

    # ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì— ëŒ€í•´ Crew ì‹¤í–‰
    results = SeoCrew().crew().kickoff_for_each(inputs=inputs_list)

    ```

---

### Case Study : Handling Structured Output (Validation)

* **Definition or When to use**: LLMì´ ë°˜í™˜í•œ JSON ë¬¸ìì—´ì„ **Python ê°ì²´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜**í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. `LLM` í´ë˜ìŠ¤ì˜ `response_format`ì´ 1ì°¨ì ìœ¼ë¡œ í˜•ì‹ì„ ìœ ë„í•˜ì§€ë§Œ, ìµœì¢…ì ìœ¼ë¡œ ê°ì²´í™”í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.

#### How to use

* **Explanation**:
* Pydantic ëª¨ë¸ì˜ `model_validate_json()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
* LLMì´ ë°˜í™˜í•œ raw string(`result`)ì„ íŒŒì‹±í•˜ì—¬ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.


* **Code block**:

    ```python
    # Source Code from Lecture (main.py)
    # LLMì€ JSON í˜•íƒœì˜ Stringì„ ë°˜í™˜í•¨
    result = llm.call(...) 

    # Stringì„ Pydantic ê°ì²´ë¡œ ë³€í™˜
    self.state.blog_post = BlogPost.model_validate_json(result)

    ```


* **Code block(Recommended Practice)**
(JSON íŒŒì‹± ì—ëŸ¬ì— ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ì•ˆì •ì„±ì„ ë†’ì…ë‹ˆë‹¤.)

    ```python
    # Recommended Practice
    try:
        self.state.blog_post = BlogPost.model_validate_json(result)
    except ValueError as e:
        print(f"JSON validation failed: {e}")
        # ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ í˜¹ì€ ê¸°ë³¸ê°’ ì„¤ì •
        self.state.blog_post = BlogPost(title="Error", subtitle="Retry needed", sections=[])

    ```